{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6ca1e5a",
   "metadata": {},
   "source": [
    "# NLP GD-08 Seq2seq으로 번역기 만들기\n",
    "\n",
    "### 2023-01-27(금)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d6e317",
   "metadata": {},
   "source": [
    "## 한글 폰트 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "922ac7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "완료!\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "%config InlineBackend.figure_format = 'retina'\n",
    " \n",
    "import matplotlib.font_manager as fm\n",
    "fontpath = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\n",
    "font = fm.FontProperties(fname=fontpath, size=9)\n",
    "plt.rc('font', family='NanumBarunGothic') \n",
    "mpl.font_manager.findfont(font)\n",
    "\n",
    "print(\"완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f5ba8a",
   "metadata": {},
   "source": [
    "## 모듈 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f880fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.1\n",
      "2.9.0\n",
      "3.5.3\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import re\n",
    "import os\n",
    "import io\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "print(pd.__version__)\n",
    "print(tf.__version__)\n",
    "print(matplotlib.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2beabe7c",
   "metadata": {},
   "source": [
    "## Step 1. 데이터 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4996c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_zip = tf.keras.utils.get_file(\n",
    "    'korean-english-park.train.tar',\n",
    "    origin = 'https://github.com/jungyeul/korean-parallel-corpora/raw/master/korean-english-news-v1/korean-english-park.train.tar.gz',\n",
    "    extract=True,\n",
    "    archive_format='tar') # format 'tar' can also unzip tar.gz file\n",
    "\n",
    "eng_path_to_file = os.path.dirname(path_to_zip) + '/korean-english-park.train.en'\n",
    "kor_path_to_file = os.path.dirname(path_to_zip) + '/korean-english-park.train.ko'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a4d446",
   "metadata": {},
   "source": [
    "### 한글 데이타 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21c56391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Size: 94123\n",
      "Example:\n",
      ">> 개인용 컴퓨터 사용의 상당 부분은 \"이것보다 뛰어날 수 있느냐?\"\n",
      ">> 북한의 핵무기 계획을 포기하도록 하려는 압력이 거세지고 있는 가운데, 일본과 북한의 외교관들이 외교 관계를 정상화하려는 회담을 재개했다.\n",
      ">> \"경호 로보트가 침입자나 화재를 탐지하기 위해서 개인적으로, 그리고 전문적으로 사용되고 있습니다.\"\n",
      ">> 수자원부 당국은 논란이 되고 있고, 막대한 비용이 드는 이 사업에 대해 내년에 건설을 시작할 계획이다.\n",
      ">> 또한 근력 운동은 활발하게 걷는 것이나 최소한 20분 동안 뛰는 것과 같은 유산소 활동에서 얻는 운동 효과를 심장과 폐에 주지 않기 때문에, 연구학자들은 근력 운동이 심장에 큰 영향을 미치는지 여부에 대해 논쟁을 해왔다.\n"
     ]
    }
   ],
   "source": [
    "with open(kor_path_to_file, \"r\") as f:\n",
    "    ko_raw = f.read().splitlines()\n",
    "\n",
    "print(\"Data Size:\", len(ko_raw))\n",
    "print(\"Example:\")\n",
    "\n",
    "for sen in ko_raw[0:100][::20]: print(\">>\", sen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b5dc4e",
   "metadata": {},
   "source": [
    "### 영문 데이타 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e383aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Size: 94123\n",
      "Example:\n",
      ">> Much of personal computing is about \"can you top this?\"\n",
      ">> Amid mounting pressure on North Korea to abandon its nuclear weapons program Japanese and North Korean diplomats have resumed talks on normalizing diplomatic relations.\n",
      ">> “Guard robots are used privately and professionally to detect intruders or fire,” Karlsson said.\n",
      ">> Authorities from the Water Resources Ministry plan to begin construction next year on the controversial and hugely expensive project.\n",
      ">> Researchers also have debated whether weight-training has a big impact on the heart, since it does not give the heart and lungs the kind of workout they get from aerobic activities such as brisk walking or running for at least 20 minutes.\n"
     ]
    }
   ],
   "source": [
    "with open(eng_path_to_file, \"r\") as f:\n",
    "    eng_raw = f.read().splitlines() # line 별로 split\n",
    "\n",
    "print(\"Data Size:\", len(eng_raw))\n",
    "print(\"Example:\")\n",
    "\n",
    "for sen in eng_raw[0:100][::20]: print(\">>\", sen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac78cfba",
   "metadata": {},
   "source": [
    "## Step 2. 데이터 정제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3769bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_corpus = [] # concatenate both corpus into one\n",
    "\n",
    "for i in range(len(eng_raw)) :\n",
    "    cleaned_corpus.append(eng_raw[i] +'\\t'+ ko_raw[i]) # eng + \\t + kor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2627a9",
   "metadata": {},
   "source": [
    "### 중복 데이타 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52507d73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94123"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleaned_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "884222ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#세트로 중복 제거\n",
    "cleaned_corpus = set(cleaned_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2792e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78968"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleaned_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf9fda7",
   "metadata": {},
   "source": [
    "### 데이타 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1ea13cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "mecab = Mecab()\n",
    "\n",
    "def preprocess_sentence(sentence, s_token=False, e_token=False, kor=False):\n",
    "    if kor :\n",
    "        sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "        sentence = re.sub(r'[\" \"]+', \" \", sentence) \n",
    "        sentence = re.sub(r\"[^ㄱ-ㅎ가-힣?.!,]+\", \" \", sentence)\n",
    "        mecab = Mecab()\n",
    "        sentence = mecab.morphs(sentence)\n",
    "        sentence = ' '.join(sentence)\n",
    "\n",
    "    else :\n",
    "        sentence = sentence.lower().strip()\n",
    "        sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "        sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "        sentence = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", sentence)\n",
    "\n",
    "        sentence = sentence.strip()\n",
    "\n",
    "        if s_token:\n",
    "            sentence = '<start> ' + sentence\n",
    "\n",
    "        if e_token:\n",
    "            sentence += ' <end>'\n",
    "            \n",
    "#         sentence = sentence.split()\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b305e131",
   "metadata": {},
   "source": [
    "### 코퍼스 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21e5b4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_corpus = []\n",
    "dec_corpus = []\n",
    "num_examples = 30000\n",
    "\n",
    "for sentence in list(cleaned_corpus)[: num_examples]:\n",
    "    eng, kor = sentence.split('\\t')\n",
    "    \n",
    "    kor = preprocess_sentence(kor, kor = True)\n",
    "    eng = preprocess_sentence(eng, s_token=True, e_token=True)\n",
    "    \n",
    "    # 한글은 mecab, 영문은 split()\n",
    "    if len(mecab.morphs(kor)) < 40 and len(eng.split()) < 42 : # token size limit to less than 40, eng 40 + 2 sp tkn\n",
    "        enc_corpus.append(kor) # 한글 정처리 후 코퍼스에 추가\n",
    "        dec_corpus.append(eng) # 영문 전처리 후 코퍼스에 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f0aeb84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23684\n",
      "64\n",
      "23684\n",
      "161\n"
     ]
    }
   ],
   "source": [
    "print(len(enc_corpus))    # 한글 코퍼스\n",
    "print(len(enc_corpus[0])) # 코퍼스[0] : 문장\n",
    "\n",
    "print(len(dec_corpus))    # 영문 코퍼스 \n",
    "print(len(dec_corpus[0])) # 코퍼스[0] : 문장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "388203a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Korean:  최근 미국 에 입국 한 아미르 칸 은 연방 요원 들 이 자신 의 컴퓨터 를 검색 할 때 마다 자존심 이 상했 다 .\n",
      "English:  <start> washington cnn amir khan says he becomes frustrated and humiliated every time he enters the united states and federal agents search his computers . <end>\n"
     ]
    }
   ],
   "source": [
    "print('Korean: ',enc_corpus[0])  #\n",
    "print('English: ',dec_corpus[0]) # "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c810ed6",
   "metadata": {},
   "source": [
    "### 문장 최대 길이 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25380440",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_maxlen(corpus, kor = False) : \n",
    "    '''\n",
    "    returns the max number of token(seq) and the index corresponding to it\n",
    "    '''\n",
    "    max_len = 0\n",
    "    idx = 0\n",
    "    \n",
    "    for i,sen in enumerate(corpus) :\n",
    "        if kor :\n",
    "            length = len(mecab.morphs(sen))\n",
    "            if max_len < length : \n",
    "                max_len = length\n",
    "                idx = i\n",
    "        else :\n",
    "            length = len(sen.split())\n",
    "            if max_len < length : \n",
    "                max_len = length\n",
    "                idx = i\n",
    "                \n",
    "    return max_len,idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7750b329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder max_seq: (39, 46)\n",
      "decoder max_seq: (41, 23)\n"
     ]
    }
   ],
   "source": [
    "print('encoder max_seq:' , find_maxlen(enc_corpus, kor=True))\n",
    "print('decoder max_seq:' , find_maxlen(dec_corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be76a4b",
   "metadata": {},
   "source": [
    "## Step 3. 데이터 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bdbbb23e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'최근 미국 에 입국 한 아미르 칸 은 연방 요원 들 이 자신 의 컴퓨터 를 검색 할 때 마다 자존심 이 상했 다 .'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_corpus[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65924da",
   "metadata": {},
   "source": [
    "### 토크화 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa15b967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize function using keras\n",
    "\n",
    "def tokenize(corpus, kor = False):\n",
    "    if kor : # 한글의 토큰화\n",
    "        mecab = Mecab()\n",
    "        sentence = []\n",
    "        \n",
    "        # 한글은 형태소 분석을 통한 분해를 실시\n",
    "        for sen in corpus :\n",
    "            sentence.append(mecab.morphs(sen))\n",
    "        \n",
    "        # 케라스 토크나이저를 사용\n",
    "        tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words = 20000, filters='')\n",
    "        tokenizer.fit_on_texts(sentence)\n",
    "        \n",
    "        # 토큰화 실시\n",
    "        tensor = tokenizer.texts_to_sequences(corpus)\n",
    "        \n",
    "        # 패딩\n",
    "        tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "            \n",
    "    else : # 영어의 토큰화\n",
    "        # 영문은 직접 케라스 토크나이저에 넣음\n",
    "        tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words = 20000, filters='')\n",
    "        tokenizer.fit_on_texts(corpus)\n",
    "        \n",
    "        # 토큰화 실시\n",
    "        tensor = tokenizer.texts_to_sequences(corpus)\n",
    "        \n",
    "        # 패딩\n",
    "        tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "\n",
    "    return tensor, tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6673221",
   "metadata": {},
   "source": [
    "### 토큰화 실시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8bd7470e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Korean Vocab Size: 25156\n",
      "English Vocab Size: 26404\n"
     ]
    }
   ],
   "source": [
    "# 토큰화하기\n",
    "enc_tensor, enc_tokenizer = tokenize(enc_corpus, kor=True)\n",
    "dec_tensor, dec_tokenizer = tokenize(dec_corpus)\n",
    "\n",
    "print(\"Korean Vocab Size:\", len(enc_tokenizer.index_word))\n",
    "print(\"English Vocab Size:\", len(dec_tokenizer.index_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97930a83",
   "metadata": {},
   "source": [
    "### 토큰화 결과 보기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23236568",
   "metadata": {},
   "source": [
    "#### 인코딩 텐서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf7d0a17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  176,    44,     8,  2107,    18,  8778,  1142,     7,   430,\n",
       "        1094,    15,     3,    92,     6,   543,    10,  1738,    37,\n",
       "         152,  1665, 10894,     3, 10895,     2,     1,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0], dtype=int32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_tensor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c1a3823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최근 미국 에 입국 한 아미르 칸 은 연방 요원 들 이 자신 의 컴퓨터 를 검색 할 때 마다 자존심 이 상했 다 . "
     ]
    }
   ],
   "source": [
    "for i in enc_tensor[0] :\n",
    "    if i != 0:\n",
    "        print(enc_tokenizer.index_word[i], end = ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79c79d3",
   "metadata": {},
   "source": [
    "#### 디코딩 텐서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "52f17f4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   3,  223,   69, 8955, 1957,   83,   21, 2535, 6683,   10, 7591,\n",
       "        458,   75,   21, 7592,    1,   85,  101,   10,  468, 3230,  946,\n",
       "         27, 2177,    2,    4,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0], dtype=int32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_tensor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4603c659",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> washington cnn amir khan says he becomes frustrated and humiliated every time he enters the united states and federal agents search his computers . <end> "
     ]
    }
   ],
   "source": [
    "for i in dec_tensor[0] :\n",
    "    if i != 0:\n",
    "        print(dec_tokenizer.index_word[i], end = ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8abc16",
   "metadata": {},
   "source": [
    "## 모델 설계"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c1a18a",
   "metadata": {},
   "source": [
    "### 바다나우 어텐션 레이어 (Bahdanau Attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "96f70a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 바다나우 어텐션 레이어\n",
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.w_dec = tf.keras.layers.Dense(units)\n",
    "        self.w_enc = tf.keras.layers.Dense(units)\n",
    "        self.w_com = tf.keras.layers.Dense(1)\n",
    "    \n",
    "    def call(self, h_enc, h_dec):\n",
    "        # h_enc shape: [batch x length x units]\n",
    "        # h_dec shape: [batch x units]\n",
    "\n",
    "        h_enc = self.w_enc(h_enc)\n",
    "        h_dec = tf.expand_dims(h_dec, 1)\n",
    "        h_dec = self.w_dec(h_dec)\n",
    "\n",
    "        score = self.w_com(tf.nn.tanh(h_dec + h_enc))\n",
    "        \n",
    "        attn = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        context_vec = attn * h_enc\n",
    "        context_vec = tf.reduce_sum(context_vec, axis=1)\n",
    "\n",
    "        return context_vec, attn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdfb23b",
   "metadata": {},
   "source": [
    "### 인코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c81becce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(enc_units,\n",
    "                                       return_sequences=True)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.gru(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe65b2d",
   "metadata": {},
   "source": [
    "### 디코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b74beb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True)\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "        self.dropout = tf.keras.layers.Dropout(0.5) # addd dropout layer\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "    def call(self, x, h_dec, enc_out):\n",
    "        context_vec, attn = self.attention(enc_out, h_dec)\n",
    "\n",
    "        out = self.embedding(x)\n",
    "        out = tf.concat([tf.expand_dims(context_vec, 1), out], axis=-1)\n",
    "        \n",
    "        out, h_dec = self.gru(out)\n",
    "        out = self.dropout(out)\n",
    "        out = tf.reshape(out, (-1, out.shape[2]))\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out, h_dec, attn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af44d514",
   "metadata": {},
   "source": [
    "## 모델 훈련"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb34674",
   "metadata": {},
   "source": [
    "### 하이퍼파라미터 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "82967e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-28 21:45:35.796884: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-01-28 21:45:35.797268: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter\n",
    "\n",
    "BATCH_SIZE     = 64\n",
    "LEARNING_RATE = 1e-4\n",
    "EPOCHS = 10\n",
    "\n",
    "SRC_VOCAB_SIZE = len(enc_tokenizer.index_word) + 1 # add 1 for padding \n",
    "TGT_VOCAB_SIZE = len(dec_tokenizer.index_word) + 1 # add 1 for padding \n",
    "\n",
    "units         = 1024 #dimension for gru\n",
    "embedding_dim = 512 # dimension for embedding\n",
    "\n",
    "encoder = Encoder(SRC_VOCAB_SIZE, embedding_dim, units)\n",
    "decoder = Decoder(TGT_VOCAB_SIZE, embedding_dim, units)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c2004e",
   "metadata": {},
   "source": [
    "### 옵티마이저"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ecd1f561",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ksh/miniforge3/envs/tutorial/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0806e78",
   "metadata": {},
   "source": [
    "### 손실함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0d66d031",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss = loss_object(real, pred)\n",
    "    \n",
    "    mask = tf.cast(mask, dtype=loss.dtype)\n",
    "    loss *= mask\n",
    "    \n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ef6180",
   "metadata": {},
   "source": [
    "### 훈련함수 정의 : 그래디언트 테이프용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fd27a560",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(src, tgt, encoder, decoder, optimizer, dec_tok):\n",
    "    bsz = src.shape[0]\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_out = encoder(src)\n",
    "        h_dec = enc_out[:, -1]\n",
    "        \n",
    "        dec_src = tf.expand_dims([dec_tok.word_index['<start>']] * bsz, 1)\n",
    "\n",
    "        for t in range(1, tgt.shape[1]):\n",
    "            pred, h_dec, _ = decoder(dec_src, h_dec, enc_out)\n",
    "\n",
    "            loss += loss_function(tgt[:, t], pred)\n",
    "            dec_src = tf.expand_dims(tgt[:, t], 1)\n",
    "        \n",
    "    batch_loss = (loss / int(tgt.shape[1]))\n",
    "\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    \n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3955641d",
   "metadata": {},
   "source": [
    "### 훈련 루프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8383374",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/371 [00:00<?, ?it/s]2023-01-28 21:45:55.061148: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-01-28 21:45:55.109816: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:45:57.729518: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:45:58.058027: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:45:58.106268: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:45:58.158375: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:45:58.209914: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:45:58.262900: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:45:58.316583: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:45:58.369667: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:45:58.423282: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:45:58.477640: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:45:58.539637: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:45:58.601674: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:45:58.663196: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:45:58.728321: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:45:58.792081: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:45:58.864277: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:45:58.924059: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:45:58.993230: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:45:59.064252: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:45:59.123941: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:45:59.192429: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:45:59.265917: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:45:59.335791: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:45:59.420814: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:45:59.491493: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:45:59.572165: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:45:59.645128: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:45:59.730920: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:45:59.806374: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:45:59.899146: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:45:59.982392: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:46:00.071453: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:46:00.152250: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:46:00.245280: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:46:00.329999: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:46:00.413977: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:46:00.494069: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:46:00.591023: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:46:00.687177: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:46:00.782940: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:46:00.864351: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:46:00.998080: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:46:01.301332: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:46:01.414143: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:46:01.552148: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:46:01.704233: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:46:01.858618: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:46:02.008718: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:46:02.158686: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:46:02.315362: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:46:02.472474: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:46:02.618590: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-28 21:46:02.736063: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:46:02.895329: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:46:03.055184: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:46:03.216939: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:46:03.377219: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:46:03.531095: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:46:03.679755: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:46:03.822985: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:46:03.965476: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:46:04.104011: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:46:04.271159: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:46:04.488338: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:46:04.702824: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:46:04.946504: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:46:05.186869: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:46:05.413640: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:46:05.631397: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:46:05.843815: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:46:06.057517: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:46:06.262308: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:46:06.473548: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:46:06.682126: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:46:06.897781: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:46:07.114087: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:46:07.326639: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:46:07.558675: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:46:07.792677: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:46:07.951406: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:46:08.188323: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-28 21:46:08.541266: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "Epoch  1:  14%|██▌                | 51/371 [02:04<09:38,  1.81s/it, Loss 4.5127]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm    # tqdm\n",
    "import random\n",
    "\n",
    "for epoch in range(EPOCHS): # EPOCHS 하이퍼파라미터 설정부에 정의\n",
    "    total_loss = 0\n",
    "    \n",
    "    idx_list = list(range(0, enc_tensor.shape[0], BATCH_SIZE)) # BATCH_SIZE 하이퍼파라미터 설정부에 정의\n",
    "    random.shuffle(idx_list)\n",
    "    t = tqdm(idx_list)    # tqdm\n",
    "\n",
    "    for (batch, idx) in enumerate(t):\n",
    "        batch_loss = train_step(enc_tensor[idx:idx+BATCH_SIZE],\n",
    "                                dec_tensor[idx:idx+BATCH_SIZE],\n",
    "                                encoder,\n",
    "                                decoder,\n",
    "                                optimizer,\n",
    "                                dec_tokenizer)\n",
    "    \n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        t.set_description_str('Epoch %2d' % (epoch + 1))    # tqdm\n",
    "        t.set_postfix_str('Loss %.4f' % (total_loss.numpy() / (batch + 1)))    # tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5ff4b8",
   "metadata": {},
   "source": [
    "## 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd49e63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence, encoder, decoder):\n",
    "    attention = np.zeros((dec_tensor.shape[-1], enc_tensor.shape[-1]))\n",
    "    \n",
    "    sentence = preprocess_sentence(sentence, kor =True) # kor True \n",
    "    inputs = enc_tokenizer.texts_to_sequences([sentence])\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs,\n",
    "                                                           maxlen=enc_tensor.shape[-1],\n",
    "                                                           padding='post')\n",
    "\n",
    "    result = ''\n",
    "\n",
    "    enc_out = encoder(inputs)\n",
    "\n",
    "    dec_hidden = enc_out[:, -1]\n",
    "    dec_input = tf.expand_dims([dec_tokenizer.word_index['<start>']], 0)\n",
    "\n",
    "    for t in range(dec_tensor.shape[-1]):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                             dec_hidden,\n",
    "                                                             enc_out)\n",
    "\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention[t] = attention_weights.numpy()\n",
    "\n",
    "        predicted_id = \\\n",
    "        tf.argmax(tf.math.softmax(predictions, axis=-1)[0]).numpy()\n",
    "\n",
    "        result += dec_tokenizer.index_word[predicted_id] + ' '\n",
    "\n",
    "        if dec_tokenizer.index_word[predicted_id] == '<end>':\n",
    "            return result, sentence, attention\n",
    "\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result, sentence, attention\n",
    "\n",
    "\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def translate(sentence, encoder, decoder):\n",
    "    result, sentence, attention = evaluate(sentence, encoder, decoder)\n",
    "\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "    \n",
    "    attention = attention[:len(result.split()), :len(sentence.split())]\n",
    "    plot_attention(attention, sentence.split(), result.split(' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5453a430",
   "metadata": {},
   "source": [
    "## 모델 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd103d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_corpus = ['오바마는 대통령이다.','시민들은 도시 속에 산다.','커피는 필요 없다.','일곱 명의 사망자가 발생했다.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e15f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test_corpus :\n",
    "    translate(i, encoder, decoder) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd65026",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38d1e214",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c283866",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca6d0e9c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "276.1875px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
