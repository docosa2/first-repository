{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42c4704d",
   "metadata": {},
   "source": [
    "# EX-10 Translator seq2seq\n",
    "\n",
    "### 곽상혁\n",
    "\n",
    "### 2022-12-09 (금)\n",
    "\n",
    "https://github.com/docosa2/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a80d2e",
   "metadata": {},
   "source": [
    "## 모듈 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8658dfa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ec8f9e",
   "metadata": {},
   "source": [
    "실습에서 구현한 번역기는 글자 단위(Character-level)에서 구현된 번역기였습니다. 하지만 실제 번역기의 경우에는 글자 단위가 아니라 단어 단위(Word-level)에서 구현되는 것이 좀 더 보편적입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1459b8a0",
   "metadata": {},
   "source": [
    "동일한 데이터셋을 사용하면서 글자 단위와는 다른 전처리와 to_categorical() 함수가 아닌 임베딩 층(Embedding layer)를 추가하여 단어 단위의 번역기를 완성시켜보겠습니다. 하지만, 단어 단위로 할 경우에는 단어의 개수가 글자 단위로 했을 경우와 비교하여 단어장의 크기(Vocabulary) 크기도 커지고, 학습 속도도 좀 더 느려집니다. 학습과 테스트 시의 원활한 진행을 위해서 데이터에서 상위 33,000개의 샘플만 사용해주세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140da75a",
   "metadata": {},
   "source": [
    "33000개 중 3000개는 테스트 데이터로 분리하여 모델을 학습한 후에 번역을 테스트 하는 용도로 사용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fadf3c",
   "metadata": {},
   "source": [
    "### 데이타 파일 읽어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "213a48bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 수 : 197463\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "      <th>cc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56018</th>\n",
       "      <td>He's acting on his own.</td>\n",
       "      <td>Il agit de son propre chef.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96810</th>\n",
       "      <td>It probably means something.</td>\n",
       "      <td>Cela signifie probablement quelque chose.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120097</th>\n",
       "      <td>This place hasn't changed much.</td>\n",
       "      <td>Cet endroit n'a pas beaucoup changé.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33665</th>\n",
       "      <td>Why don't you sing?</td>\n",
       "      <td>Pourquoi ne chantez-vous pas ?</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161022</th>\n",
       "      <td>Why is autumn called \"fall\" in America?</td>\n",
       "      <td>Pourquoi l'automne s'appelle \"fall\" aux États-...</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            eng  \\\n",
       "56018                   He's acting on his own.   \n",
       "96810              It probably means something.   \n",
       "120097          This place hasn't changed much.   \n",
       "33665                       Why don't you sing?   \n",
       "161022  Why is autumn called \"fall\" in America?   \n",
       "\n",
       "                                                      fra  \\\n",
       "56018                         Il agit de son propre chef.   \n",
       "96810           Cela signifie probablement quelque chose.   \n",
       "120097               Cet endroit n'a pas beaucoup changé.   \n",
       "33665                      Pourquoi ne chantez-vous pas ?   \n",
       "161022  Pourquoi l'automne s'appelle \"fall\" aux États-...   \n",
       "\n",
       "                                                       cc  \n",
       "56018   CC-BY 2.0 (France) Attribution: tatoeba.org #1...  \n",
       "96810   CC-BY 2.0 (France) Attribution: tatoeba.org #3...  \n",
       "120097  CC-BY 2.0 (France) Attribution: tatoeba.org #3...  \n",
       "33665   CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
       "161022  CC-BY 2.0 (France) Attribution: tatoeba.org #3...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "file_path = os.getenv('HOME')+'/aiffel/translator_seq2seq/data/fra.txt'\n",
    "lines = pd.read_csv(file_path, names=['eng', 'fra', 'cc'], sep='\\t')\n",
    "print('전체 샘플의 수 :',len(lines))\n",
    "lines.sample(5) #샘플 5개 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f65e27c",
   "metadata": {},
   "source": [
    "### 중복 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d298ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 전체 샘플의 수 : 138912\n"
     ]
    }
   ],
   "source": [
    "lines = lines.drop_duplicates(subset='eng')\n",
    "print('중복 제거 후 전체 샘플의 수 :',len(lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b805c57",
   "metadata": {},
   "source": [
    "### 불필요한 칼럼 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54cc9b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = lines[['eng', 'fra']][:36000].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65d3f735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Va !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Salut !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Cours !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Run.</td>\n",
       "      <td>Cours !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Who?</td>\n",
       "      <td>Qui ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35995</th>\n",
       "      <td>I like walking to work.</td>\n",
       "      <td>J'aime aller au travail à pied.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35996</th>\n",
       "      <td>I like watching people.</td>\n",
       "      <td>J'aime regarder les gens.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35997</th>\n",
       "      <td>I like you as a friend.</td>\n",
       "      <td>Je vous apprécie en tant qu'ami.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35998</th>\n",
       "      <td>I live across the hall.</td>\n",
       "      <td>Je vis de l'autre côté du couloir.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35999</th>\n",
       "      <td>I live in a rural area.</td>\n",
       "      <td>Je vis en zone rurale.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           eng                                 fra\n",
       "0                          Go.                                Va !\n",
       "1                          Hi.                             Salut !\n",
       "2                         Run!                             Cours !\n",
       "3                         Run.                             Cours !\n",
       "4                         Who?                               Qui ?\n",
       "...                        ...                                 ...\n",
       "35995  I like walking to work.     J'aime aller au travail à pied.\n",
       "35996  I like watching people.           J'aime regarder les gens.\n",
       "35997  I like you as a friend.    Je vous apprécie en tant qu'ami.\n",
       "35998  I live across the hall.  Je vis de l'autre côté du couloir.\n",
       "35999  I live in a rural area.              Je vis en zone rurale.\n",
       "\n",
       "[36000 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca08f412",
   "metadata": {},
   "source": [
    "### 셔플"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbeab6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = lines.iloc[np.random.permutation(lines.index)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e7eed55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I play squash.</td>\n",
       "      <td>Je joue au squash.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You look like a cop.</td>\n",
       "      <td>T'as l'air d'un flic.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm bringing wine.</td>\n",
       "      <td>J'apporte du vin.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The sea is blue.</td>\n",
       "      <td>La mer est bleue.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I think we can manage.</td>\n",
       "      <td>Je pense que nous pouvons gérer.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35995</th>\n",
       "      <td>Tom became indignant.</td>\n",
       "      <td>Tom s'est indigné.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35996</th>\n",
       "      <td>Please keep in touch.</td>\n",
       "      <td>Veuillez garder le contact.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35997</th>\n",
       "      <td>I flushed the toilet.</td>\n",
       "      <td>J'ai tiré la chasse d'eau.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35998</th>\n",
       "      <td>I came alone.</td>\n",
       "      <td>Je suis venu seul.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35999</th>\n",
       "      <td>I know you can make it.</td>\n",
       "      <td>Je sais que tu peux y arriver.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           eng                               fra\n",
       "0               I play squash.                Je joue au squash.\n",
       "1         You look like a cop.             T'as l'air d'un flic.\n",
       "2           I'm bringing wine.                 J'apporte du vin.\n",
       "3             The sea is blue.                 La mer est bleue.\n",
       "4       I think we can manage.  Je pense que nous pouvons gérer.\n",
       "...                        ...                               ...\n",
       "35995    Tom became indignant.                Tom s'est indigné.\n",
       "35996    Please keep in touch.       Veuillez garder le contact.\n",
       "35997    I flushed the toilet.        J'ai tiré la chasse d'eau.\n",
       "35998            I came alone.                Je suis venu seul.\n",
       "35999  I know you can make it.    Je sais que tu peux y arriver.\n",
       "\n",
       "[36000 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134f3d61",
   "metadata": {},
   "source": [
    "### Step 1. 정제, 정규화, 전처리 (영어, 프랑스어 모두!)\n",
    "---\n",
    "\n",
    "글자 단위가 아닌 단어 단위의 번역기를 하기 위해서는 글자 단위에서는 신경쓰지 않았던 몇 가지 추가적인 전처리가 필요합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37780fde",
   "metadata": {},
   "source": [
    "1. 구두점(Punctuation)을 단어와 분리해주세요.\n",
    "\n",
    "일반적으로 영어권 언어의 경우에는 띄어쓰기 단위로 단어를 분리합니다. 토큰화(Tokenization) 라고도 불리는 이 작업은 어디서부터 어디까지가 하나의 단어인지를 구분하는 작업인데요, 그런데 띄어쓰기를 해주기 전에 구두점을 분리하는 작업이 필요할 때가 있습니다.\n",
    "예를 들어서 'he is a good boy!'라는 문장이 있을 때, 이를 띄어쓰기 단위로 토큰화한다면 ['he', 'is', 'a', 'good', 'boy!']가 됩니다. 그런데 실제로 !는 boy와 붙어있는 한 단어가 아니므로 좀 더 올바른 전처리는 ['he', 'is', 'a', 'good', 'boy', '!']가 맞습니다.\n",
    "!나 ? 또는 온점과 같은 특수문자들을 구두점(punctuation)이라고 부릅니다. 이들을 토큰화하기 전에 단어와 미리 분리시켜주세요!\n",
    "\n",
    "> 분리 전 : he is a Good boy!  \n",
    "> 분리 후 : he is a Good boy !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f5619b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def Seperate_punctuations(sentence: str) -> str:\n",
    "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence) \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cab4aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert Seperate_punctuations('This Is, So To Speak, A Kind Of A Test Sentence.') == ('This Is ,  So To Speak ,  A Kind Of A Test Sentence . '), 'Error in converter to seperate punctuations.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "baa6b202",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sepearate_entire_punctuations_for(df: pd.DataFrame) -> None:\n",
    "    for index, row in df.iterrows():\n",
    "        row['eng'] = Seperate_punctuations(row['eng'])\n",
    "        row['fra'] = Seperate_punctuations(row['fra'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "095bd39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sepearate_entire_punctuations_for(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21a7f432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I play squash .</td>\n",
       "      <td>Je joue au squash .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You look like a cop .</td>\n",
       "      <td>T'as l'air d'un flic .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm bringing wine .</td>\n",
       "      <td>J'apporte du vin .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The sea is blue .</td>\n",
       "      <td>La mer est bleue .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I think we can manage .</td>\n",
       "      <td>Je pense que nous pouvons gérer .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        eng                                 fra\n",
       "0          I play squash .                 Je joue au squash . \n",
       "1    You look like a cop .              T'as l'air d'un flic . \n",
       "2      I'm bringing wine .                  J'apporte du vin . \n",
       "3        The sea is blue .                  La mer est bleue . \n",
       "4  I think we can manage .   Je pense que nous pouvons gérer . "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9f4000",
   "metadata": {},
   "source": [
    "2. 소문자로 바꿔주세요.\n",
    "\n",
    "기계가 보기에는 스펠링이 같더라도 대문자로 된 단어와 소문자로 된 단어는 서로 다른 단어입니다. 예를 들어 'Good'과 'good'은 기계가 보기에는 다른 단어입니다. 그래서 모든 문장에 대해서 전부 영어로 바꿔주는 작업을 하겠습니다.\n",
    "\n",
    "> 변환 전 : he is a Good boy !  \n",
    "> 변환 후 : he is a good boy !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39dd6147",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def Convert_to_lower_case(sentence: str) -> str:\n",
    "    sentence = sentence.lower().strip()\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12c87ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert Convert_to_lower_case('This Is A Test Sentence.') == ('this is a test sentence.'), 'Error in converter for lower case.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "793b91d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Convert_to_lower_cases_for(df: pd.DataFrame) -> None:\n",
    "    for index, row in df.iterrows():\n",
    "        row['eng'] = Convert_to_lower_case(row['eng'])\n",
    "        row['fra'] = Convert_to_lower_case(row['fra'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52ac7b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "Convert_to_lower_cases_for(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b94e0094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i play squash .</td>\n",
       "      <td>je joue au squash .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>you look like a cop .</td>\n",
       "      <td>t'as l'air d'un flic .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i'm bringing wine .</td>\n",
       "      <td>j'apporte du vin .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the sea is blue .</td>\n",
       "      <td>la mer est bleue .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i think we can manage .</td>\n",
       "      <td>je pense que nous pouvons gérer .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       eng                                fra\n",
       "0          i play squash .                je joue au squash .\n",
       "1    you look like a cop .             t'as l'air d'un flic .\n",
       "2      i'm bringing wine .                 j'apporte du vin .\n",
       "3        the sea is blue .                 la mer est bleue .\n",
       "4  i think we can manage .  je pense que nous pouvons gérer ."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5905f7",
   "metadata": {},
   "source": [
    "### 디코더에 시작토큰과 종료 토큰 삽입"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cba97457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 수 : 36000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27224</th>\n",
       "      <td>i'm sorry i'm late .</td>\n",
       "      <td>&lt;sos&gt; excusez mon retard . &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>i have a husband .</td>\n",
       "      <td>&lt;sos&gt; j'ai un mari . &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29900</th>\n",
       "      <td>i like her dark eyes .</td>\n",
       "      <td>&lt;sos&gt; j'aime ses yeux foncés . &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18494</th>\n",
       "      <td>i hope i see it again .</td>\n",
       "      <td>&lt;sos&gt; j'espère le revoir . &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26871</th>\n",
       "      <td>i'm quite tired .</td>\n",
       "      <td>&lt;sos&gt; je suis assez fatiguée . &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           eng                                   fra\n",
       "27224     i'm sorry i'm late .      <sos> excusez mon retard . <eos>\n",
       "700         i have a husband .            <sos> j'ai un mari . <eos>\n",
       "29900   i like her dark eyes .  <sos> j'aime ses yeux foncés . <eos>\n",
       "18494  i hope i see it again .      <sos> j'espère le revoir . <eos>\n",
       "26871        i'm quite tired .  <sos> je suis assez fatiguée . <eos>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sos_token = '<sos>'\n",
    "eos_token = '<eos>'\n",
    "lines.fra = lines.fra.apply(lambda x : '<sos> '+ x + ' <eos>')\n",
    "print('전체 샘플의 수 :',len(lines))\n",
    "lines.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a797eb7",
   "metadata": {},
   "source": [
    "3. 띄어쓰기 단위로 토큰화를 수행하세요.\n",
    "\n",
    "띄어쓰기 단위로 토큰화를 수행해서 단어를 분리하는 작업을 해주세요. 기계는 이렇게 분리된 토큰들을 각각 하나의 단어로 인식할 수 있게 됩니다.\n",
    "\n",
    "> 토큰화 전 : 'he is a good boy !'  \n",
    "> 토큰화 후 : ['he', 'is', 'a', 'good', 'boy', '!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "469f293f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Tokenize_by_word(sentence: str) -> list:\n",
    "    return sentence.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8111bc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert Tokenize_by_word('he is a good boy !') == ['he', 'is', 'a', 'good', 'boy', '!'], 'word tokenizer error.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1f49f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Tokenize_by_word_for(df: pd.DataFrame) -> (list, list): # english, french\n",
    "    encode_sentences = []\n",
    "    decode_sentences = []\n",
    "    for index, row in df.iterrows():\n",
    "        encode_tokens = Tokenize_by_word(row['eng'])\n",
    "        decode_tokens = Tokenize_by_word(row['fra'])\n",
    "        encode_sentences.append(encode_tokens)\n",
    "        decode_sentences.append(decode_tokens)\n",
    "    return encode_sentences, decode_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "88e86708",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_corpus, french_corpus = Tokenize_by_word_for(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cfca66",
   "metadata": {},
   "source": [
    "### Step 2. 디코더의 문장에 시작 토큰과 종료 토큰을 넣어주세요.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c790f3",
   "metadata": {},
   "source": [
    "글자 단위 번역기를 구현할 때와 마찬가지로 디코더의 입력 시퀀스 맨 앞에는 시작을 의미하는 토큰인 <sos>가 필요합니다. 그리고 교사 강요를 수행할 때, 디코더의 실제값이 되는 디코더의 레이블 시퀀스에는 종료를 의미하는 종료 토큰 <eos>가 필요합니다.\n",
    "예를 들어 번역 문장이 \"Courez!\" 였다고 한다면, Step 1을 거친 후에는 다음과 같은 결과를 얻습니다.\n",
    "\n",
    "> Step 1을 수행한 후 : ['courez', '!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b3477f14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'play', 'squash', '.']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_corpus[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6077e8e1",
   "metadata": {},
   "source": [
    "이 문장에 대해서 각각 디코더의 입력 시퀀스와 레이블 시퀀스를 만들면 다음과 같습니다.\n",
    "\n",
    "> 입력 시퀀스 : ['< sos >', 'courez', '!']  \n",
    "> 레이블 시퀀스 : ['courez', '!', '< eos >']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a86dae22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos>', 'je', 'joue', 'au', 'squash', '.', '<eos>']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "french_corpus[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9ca6e7",
   "metadata": {},
   "source": [
    "참고로 Step 2가 반드시 Step 1이 끝난 후에 이루어질 필요는 없습니다!  \n",
    "Step 1을 수행하는 중간에 수행해도 상관없습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e25481f",
   "metadata": {},
   "source": [
    "### Step 3. 케라스의 토크나이저로 텍스트를 숫자로 바꿔보세요.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac352271",
   "metadata": {},
   "source": [
    "딥러닝 모델은 텍스트가 아닌 숫자를 처리합니다. 케라스 토크나이저를 사용해서 각 단어를 고유한 정수로 바꿔보세요.\n",
    "케라스 토크나이저의 사용법은 아래의 링크에서 2. 케라스(Keras)의 텍스트 전처리에 설명되어 있습니다.\n",
    "\n",
    "[위키독스](https://wikidocs.net/31766)  \n",
    "\n",
    "위 링크의 가이드를 통해서 영어와 프랑스어에 대한 토크나이저를 각각 생성하고, tokenizer.texts_to_sequences()를 사용하여 모든 샘플에 대해서 정수 시퀀스로 변환해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e660d370",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d592698",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(corpus):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)        \n",
    "    return tensor, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc8f0266",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_text, english_tokenizer = tokenize(english_corpus)\n",
    "french_text, french_tokenizer = tokenize(french_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0c47a93f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 186, 3974, 1], [7, 91, 27, 4, 1437, 1], [12, 3975, 435, 1]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_text[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fc1becd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 4, 327, 68, 5658, 3, 2],\n",
       " [1, 1301, 72, 156, 1939, 3, 2],\n",
       " [1, 5659, 45, 418, 3, 2]]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "french_text[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9b3cf1",
   "metadata": {},
   "source": [
    "####  인코딩 상태 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4302d166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 문장수 36000\n",
      "프랑스어 문장수 36000\n"
     ]
    }
   ],
   "source": [
    "print('영어 문장수', len(english_text))\n",
    "print('프랑스어 문장수', len(french_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b7a48c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 단어수: 6681\n",
      "프랑스어 단어수: 11040\n"
     ]
    }
   ],
   "source": [
    "english_vocab_size = len(english_tokenizer.word_index) + 1\n",
    "french_vocab_size = len(french_tokenizer.word_index) + 1\n",
    "print('영어 단어수:', english_vocab_size)\n",
    "print('프랑스어 단어수:', french_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "41683c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 문장 최대 길이 : 9\n",
      "프랑스 문장 최대 길이 : 15\n"
     ]
    }
   ],
   "source": [
    "max_eng_len = max([len(s) for s in english_text])\n",
    "max_fre_len = max([len(s) for s in french_text])\n",
    "print('영어 문장 최대 길이 :', max_eng_len)\n",
    "print('프랑스 문장 최대 길이 :', max_fre_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621279f5",
   "metadata": {},
   "source": [
    "### Step 4. 임베딩 층(Embedding layer) 사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb44f517",
   "metadata": {},
   "source": [
    "이번에는 입력이 되는 각 단어를 임베딩 층을 사용하여 벡터화하겠습니다.\n",
    "임베딩 층을 사용하는 방법과 그 설명에 대해서는 아래의 링크의 1. 케라스 임베딩 층(Keras Embedding layer) 을 참고하세요.\n",
    "\n",
    "[위키독스](https://wikidocs.net/33793)\n",
    "\n",
    "실제 번역기 구현을 위해서 사용할 수 있는 인코더 코드의 예시는 다음과 같습니다. 이를 통해서 인코더와 디코더의 임베딩 층을 각각 구현해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "674c89cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Masking\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fc53e922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(french_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "382e7a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = english_text\n",
    "decoder_input = [sentence[:-1] for sentence in french_text]\n",
    "decoder_target = [sentence[1:] for sentence in french_text]\n",
    "# decoder_input = [[ char for char in line if char != french_tokenizer.word_index[eos_token] ] for line in french_text] \n",
    "# decoder_target = [[ char for char in line if char != french_tokenizer.word_index[sos_token] ] for line in french_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7c41e6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 데이타 크기(shape) : (36000, 9)\n",
      "프랑스어 입력 데이타 크기(shape) : (36000, 15)\n",
      "프랑스어 타겟 데이타 크기(shape) : (36000, 15)\n"
     ]
    }
   ],
   "source": [
    "encoder_input = pad_sequences(encoder_input, maxlen = max_eng_len, padding='post')\n",
    "decoder_input = pad_sequences(decoder_input, maxlen = max_fre_len, padding='post')\n",
    "decoder_target = pad_sequences(decoder_target, maxlen = max_fre_len, padding='post')\n",
    "print('영어 데이타 크기(shape) :',np.shape(encoder_input))\n",
    "print('프랑스어 입력 데이타 크기(shape) :',np.shape(decoder_input))\n",
    "print('프랑스어 타겟 데이타 크기(shape) :',np.shape(decoder_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a6b8a714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 학습데이터의 크기(shape) : (30000, 9)\n",
      "프랑스어 학습 입력데이터의 크기(shape) : (30000, 15)\n",
      "프랑스어 학습 출력데이터의 크기(shape) : (30000, 15)\n",
      "\n",
      "영어 학습데이터의 크기(shape) : (3000, 9)\n",
      "프랑스어 학습 입력데이터의 크기(shape) : (3000, 15)\n",
      "프랑스어 학습 출력데이터의 크기(shape) : (3000, 15)\n",
      "\n",
      "영어 학습데이터의 크기(shape) : (3000, 9)\n",
      "프랑스어 학습 입력데이터의 크기(shape) : (3000, 15)\n",
      "프랑스어 학습 출력데이터의 크기(shape) : (3000, 15)\n"
     ]
    }
   ],
   "source": [
    "test_num = 3000\n",
    "val_num = 3000\n",
    "\n",
    "encoder_input_train = encoder_input[:-6000]\n",
    "decoder_input_train = decoder_input[:-6000]\n",
    "decoder_target_train = decoder_target[:-6000]\n",
    "\n",
    "encoder_input_val = encoder_input[-6000:-3000]\n",
    "decoder_input_val = decoder_input[-6000:-3000]\n",
    "decoder_target_val = decoder_target[-6000:-3000]\n",
    "\n",
    "encoder_input_test = encoder_input[-3000:]\n",
    "decoder_input_test = decoder_input[-3000:]\n",
    "decoder_target_test = decoder_target[-3000:]\n",
    "\n",
    "\n",
    "print('영어 학습데이터의 크기(shape) :',np.shape(encoder_input_train))\n",
    "print('프랑스어 학습 입력데이터의 크기(shape) :',np.shape(decoder_input_train))\n",
    "print('프랑스어 학습 출력데이터의 크기(shape) :',np.shape(decoder_target_train))\n",
    "print()\n",
    "print('영어 학습데이터의 크기(shape) :',np.shape(encoder_input_val))\n",
    "print('프랑스어 학습 입력데이터의 크기(shape) :',np.shape(decoder_input_val))\n",
    "print('프랑스어 학습 출력데이터의 크기(shape) :',np.shape(decoder_target_val))\n",
    "print()\n",
    "print('영어 학습데이터의 크기(shape) :',np.shape(encoder_input_test))\n",
    "print('프랑스어 학습 입력데이터의 크기(shape) :',np.shape(decoder_input_test))\n",
    "print('프랑스어 학습 출력데이터의 크기(shape) :',np.shape(decoder_target_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0ac8e1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   2  186 3974    1    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7620302a",
   "metadata": {},
   "source": [
    "#### 인코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "902f8e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 텐서 정의 및 생성.\n",
    "eng_vocab_size = english_vocab_size\n",
    "fra_vocab_size = french_vocab_size\n",
    "\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "enc_emb_layer =  Embedding(eng_vocab_size, 128)(encoder_inputs)\n",
    "encoder_lstm = LSTM(units=256, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb_layer)\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9594abe3",
   "metadata": {},
   "source": [
    "#### 디코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "272c61a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb_layer = Embedding(fra_vocab_size, 128)\n",
    "dec_emb_layer = dec_emb_layer(decoder_inputs) \n",
    "decoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb_layer, initial_state=encoder_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03176e71",
   "metadata": {},
   "source": [
    "#### 출력층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "718bd4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_softmax_layer = Dense(fra_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188f4a9b",
   "metadata": {},
   "source": [
    "### Step 5. 모델 구현하기\n",
    "---\n",
    "\n",
    "글자 단위 번역기에서 구현한 모델을 참고로 단어 단위 번역기의 모델을 완성시켜보세요! 이때는 label이 integer 값이므로 categorical entropy loss가 아닌 sparse categorical entropy loss를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "21c94257",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d275141e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5f0e3d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 128)    855168      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 128)    1413120     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 256), (None, 394240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 256),  394240      embedding_1[0][0]                \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 11040)  2837280     lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 5,894,048\n",
      "Trainable params: 5,894,048\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9535bb26",
   "metadata": {},
   "source": [
    "### 모델 훈련하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "835428d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 15)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_target_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "01f05cb7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 182s 5ms/step - loss: 1.8318\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 153s 5ms/step - loss: 1.9961\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 154s 5ms/step - loss: 1.9267\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 153s 5ms/step - loss: 1.8857\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 153s 5ms/step - loss: 1.8594\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 153s 5ms/step - loss: 1.8438\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 153s 5ms/step - loss: 1.8307\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 152s 5ms/step - loss: 1.8250\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 153s 5ms/step - loss: 1.8169\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 152s 5ms/step - loss: 1.8118\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
    "          validation_data = ([encoder_input_val, decoder_input_val], decoder_target_val), \n",
    "          batch_size=128, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "40a78e25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f6c769c4700>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(15,6))\n",
    "\n",
    "for k,v in history.history.items():\n",
    "    plt.plot(history.history[k], label=k)\n",
    "plt.ylim(0, 3)\n",
    "plt.title('RMS Prop, Batch Size 128')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1591f033",
   "metadata": {},
   "source": [
    "### Step 6. 모델 평가하기\n",
    "---\n",
    "단어 단위 번역기를 이용하여 훈련 데이터의 샘플과 테스트 데이터의 샘플로 번역 문장을 만들어보고 정답 문장과 번역 문장을 비교해보세요. 이전 스텝들에서 우리가 공부했던 모델의 경우 글자 단위에서 구현된 번역기이며 현재 프로젝트를 진행할 때 사용하는 모델은 단어 단위에서 구현되는 번역기입니다.\n",
    "\n",
    "> Embedding layer가 추가되기 때문에 학습했던 내용 그대로 사용할 경우 shape에서 error가 발생합니다.\n",
    "> decode sentence를 구성할 때 고민해보세요!!\n",
    "\n",
    "고민하다 풀리지 않을 경우에는 하단 내용 참고해주세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68dd2b0",
   "metadata": {},
   "source": [
    "루브릭  \n",
    "아래의 기준을 바탕으로 프로젝트를 평가합니다.  \n",
    "평가문항\t상세기준\n",
    "\n",
    "1. 번역기 모델 학습에 필요한 텍스트 데이터 전처리가 잘 이루어졌다.  \n",
    "구두점, 대소문자, 띄어쓰기 등 번역기 모델에 요구되는 전처리가 정상적으로 진행되었다.  \n",
    "\n",
    "2. seq2seq 기반의 번역기 모델이 정상적으로 구동된다.  \n",
    "seq2seq 모델 훈련결과를 그래프로 출력해보고, validation loss그래프가 우하향하는 경향성을 보이며 학습이 진행됨이 확인되었다.\n",
    "\n",
    "3. 테스트 결과 의미가 통하는 수준의 번역문이 생성되었다.  \n",
    "테스트용 디코더 모델이 정상적으로 만들어졌으며, input(영어)와 output(프랑스어) 모두 한글로 번역해서 결과를 출력해보았고, 둘의 내용이 유사함을 확인하였다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa24ff08",
   "metadata": {},
   "source": [
    "### 고찰\n",
    "1. 단어 단위 임베딩에 따른 인풋 벡터의 변화에 대한 이해가 좀 어려웠다.\n",
    "2. 중복되는 문장이 있어 이를 제거 후 성능이 좋아짐을 확인했다. 전처리와 데이타를 살펴보는 과정은 늘 중요함을 알 수 있었다.\n",
    "3. 모델 학습에 소요되는 시간이 많아 다양한 실험을 해보지 못한 점이 아쉬웠다.\n",
    "4. 모델 학습 시도 시 오류가 발생하여 디버깅에 많은 시간을 소모했는데, 원인은 로스 함수의 선택에 문제가 있었다. 항상 기본에 충실해야 한다는 점을 깨달았다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ed8372",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947d95fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "392.796875px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
